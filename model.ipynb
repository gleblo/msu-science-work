{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf complicater.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-sNZlH_K1nW",
        "colab_type": "code",
        "outputId": "c2bf2528-feec-4295-b9aa-d1566b3206ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from tensorflow.contrib.layers import xavier_initializer\n",
        "import tensorflow as tf\n",
        "import mnist_handling as mn\n",
        "\n",
        "tf.set_random_seed(66666)\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "xs = tf.placeholder(tf.float32, [None, 784])\n",
        "ys = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-eaac353e4ddc>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SdlsBmOMUau",
        "colab_type": "code",
        "outputId": "967ada0e-5ca6-4b2c-ad11-a866972e503b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.hist((np.argmax(mnist.train.labels,axis = 1),np.argmax(mnist.test.labels,axis = 1)))\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxojhEJSOqhb",
        "colab_type": "code",
        "outputId": "50ffd078-611c-4b83-fecd-7825438374ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "for i in range(5):\n",
        "  plt.subplot(1, 5, i+1)\n",
        "  plt.imshow(np.squeeze(np.reshape(mnist.train.images[i], newshape=[28,28])), cmap='gray')\n",
        "  plt.title(np.argmax(mnist.train.labels[i],axis = 0))\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABpCAYAAAAnQqjlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASnklEQVR4nO3de7SV87rA8e8jpYZQLqVRKLTdNiOJ\no+N+iW0z3AdCLmOTWwhHJ8QhpO2Su0PUOZ2xt2vi5BpCpIGUSxKxHVHaCClSVM/5Y86nd97WWnOt\n+b7zfd85n88Ya6z1zrWa85lP73rX8/6uoqo455xLr7XiDsA551xl/ELunHMp5xdy55xLOb+QO+dc\nyvmF3DnnUs4v5M45l3J+IXfOuZSryQu5iPxc8LFKRO6MO664icjfRGShiCwRkbkickbcMSWFiPQU\nkeUi8re4Y0kKETlBROaIyC8i8g8R2SvumOIiIoNE5B0RWSEi/x13PIXWjjuAKKhqe/taRNoD/wQe\niy+ixLgB+IuqrhCRbYFXReRdVZ0Rd2AJcDcwPe4gkkJE+gF/BY4H3ga6xBtR7L4GrgMOBtrFHEuR\nmqzICxwDfAu8HncgcVPV2aq6wg6zH1vFGFIiiMgJwGJgctyxJMg1wHBVfVNVV6vqAlVdEHdQcVHV\nCar6JPB93LGUUg8X8lOB/1FfiwAAEblHRJYBHwMLgWdjDilWIrI+MBy4OO5YkkJEWgF9gE1E5DMR\nmS8id4lI4ipRl1HTF3IR2QLYBxgXdyxJoarnAusBewETgBWN/4uady0wRlXnxx1IgnQGWgPHkjlP\negE7A8PiDMo1rKYv5MAAYKqq/l/cgSSJqq5S1alAN+CcuOOJi4j0Ag4Ebo07loT5Nfv5TlVdqKqL\ngFHAn2OMyTWiJjs7c5wCjIw7iARbm/puI98X6A58KSIA7YFWIrK9qvaOMa5YqeqPIjKfTB/Kmofj\nisc1rWYrchH5V6ArPloFABHplB1O1l5EWonIwUB/6ruDbzSZP2S9sh/3As+QGZlQ7/4LOD973nQE\nLgKejjmm2IjI2iLSFmhF5o99WxFJTCGcmEAicCowQVWXxh1IQiiZZpR7yfwBnwcMVtWJsUYVI1Vd\nBiyzYxH5GViuqt/FF1ViXAtsDMwFlgOPAtfHGlG8hgH/kXN8MpmRPVfHEk0B8cEczjmXbjXbtOKc\nc/XCL+TOOZdyFV3IReRPIvJJdtLA0LCCSjPPSWmel2Kek2Kek5ZpcRt5dvbXXKAfMJ/MOhX9VfWj\n8MJLF89JaZ6XYp6TYp6TlqukIt8N+ExVP1fV34CHgSPCCSu1PCeleV6KeU6KeU5aqJLhh12Br3KO\n5wP/0tg/EJG6GCIjIt+p6iZ4TnItz/m60bx4Tkqro7wYz0lgUfaaUlLk48hFZCAwMOrXSZh5jX2z\nTnPyc2Pf9JyUVqd5aVSd5qTRa0olF/IFwGY5x92yj+VR1dFkZtDV019P4zkJtMn5uigvnhM/V0rw\nnJSpkjby6UBPEekhIm2AE4C6nSVYoI3npEhbP1eKeE5K8Jw0X4srclVdKSKDgElk1h8Yq6qzQ4ss\n3f4AzMFzkutL/Fwp5DkpzXPSTBW1kavqs9T5xgQN+FBV+8QdRML85Dkp4jkpQVX/EHcMaVPLi2Y5\n50Ky1lqZVthbbrkFgEGDBgHQt29fAN555514AnOAT9F3zrnU84rcOdegTp06AXDttdcCMHBg/qi/\nHj16APVVkd9///0AnHTSSQDsueeeAMycOTO2mLwid865lPOKvI5sscUWAJxxxhkAXHHFFQDYejvZ\n7c6YM2cOAMOGZfbafeKJJ6oap4tfly5dABgyZAhQXIm//vrrALz11lvVDSwBvvjiCwDatm0LQM+e\nPQGvyJ1zzlXAK/IatskmmaUZLrvsMiBo09too42AoBIvXAFzm222AWDUqFFAUH0tWrQo4oij06ZN\nZhLl5MmZLUr32GMPILgLWbx4MQA77bQTAF999VXhU9SFtdfOXBIuv/xyIBidYu666y4ALrnkEgB+\n++23KkaXDF9++WXe8SmnnALAI488Ekc4gFfkzjmXejVTkZ9++ulAUF1+//33AGy33XYATJs2DYCp\nU6fGEF11Wdu3jTQobAO3Y6s6v/suf6/hjTfeGIDu3bsDMGXKFAB22GGHCKOOhlXiY8aMAYJK3Dz5\n5JMAjBw5EoCvv/66rOft3LkzAN98800ocSbFDTfcABRX4vfddx8A559/ftVjSrrff/897hC8InfO\nubTzC7lzzqVcIppW+vfvD0Dv3r2BoJmkOTp06JB3vGrVKiC4tf71118BWLZsGQCzZs0C4LjjjgOK\nmxfS7MgjjwQa7sz86KPMzln77bcfUNyJaRMcrEnFOj/TyDrlrKPX3H333QBceumlACxfvpxy3Hzz\nzUBwjlrzFcBtt91WWbAxuuaaa4AgX8Y6Ny+++OKqx5RURx11VN7xQw89FFMkAa/InXMu5Vq8+XKL\nXqxgEXhbgOfCCy8EoFWrVlWLxbzyyitAcFcQUufVjHJXtQtzYfxtt90WgOnTpwNBh6/dbVjlfdFF\nFwEwePBgAEaMGAEUD6uyc2P16tUAnHPOOWu+N3r06OaGV9WcWMfs22+/DUC7du0A+PnnzKY8G264\nIQArV64s6/n69MmE/vzzz+f9+9xKtQUVedk5gWg2Udh9990BeOaZZ4DgfVnn5rnnngsE50A1qKqU\n+7PV3FiiV69eQDAJasmSJQBsvvnmQHDXH5FGzxWvyJ1zLuVibSO39mmrxD/44AOgvL9sNozQho81\npV+/fkAweN+G1lk7sbVzHX/88UA628w//vhjAHbddVcgqMAL28BtuvWZZ54JBNW1VeTWBmhVmFXm\nEyZMiCz2sA0dOhQIKnGrvA8//PC843JZW7pVrDbkrNzzL6mGDx8OBO/rqaeeAoK2/2pW4km3zjrr\nANC6dWsgyE3ElXhZvCJ3zrmUi7UiP+CAA4CgPfOll14CYOnSpaG/llXw48aNA+Dpp58GgglDVplb\nxW7t92lklXlD7G7jk08+AYK2dGs7t2rWJhA1VNkn2S677JJ3bG3br776at7jdjdoo5sKbbXVVgDs\ns88+eY+PHz8eCBZQSqsdd9wx79iWaF2woGjP47p3zDHHxB1Cg7wid865lIu1Ip87d27e52r4/PPP\nAbjqqqsAeOyxx/K+b9Vomitys/feewPBaBarxG2ZWhsfbr3wtsiWtYnbzx9yyCFVijg61r5pdttt\nNwCuu+46AA488MCynsdGNdlIn7Q69NBDAdh0000BePzxx4HgTtUVs6V9k8grcuecS7lEzOx00Tjx\nxBOBYHRK4aJZdmyVeGGb+B133AHEu2B+S914440AjB07Fgj6QF5++WUguFuxTYXLZW3Is2fPDiXO\nuBx99NF5x1aRt3ReieXRR7nEwyty55xLubqryG12oo21LmTbN+WOepgxY0b0gUWosMpq6Ng2kLDZ\nimmsxI3NtjO2YcK+++6b97j1D9h2dl27dgUaXq61VjYZts1FjI1cKpfNCLXfJ8ubzQ354YcfKg0x\nMWxEk809MU2NDqsmr8idcy7laqYitx7lk08+GQjWEWno56w9uFD79u2BoC0VYIMNNggtzmp68MEH\ngWDTZdswwkaxrLvuunk/byN50lyJG2sbb2grsocffhgINtew1TJtW7xCb7zxBgDPPvtsqHFWW8eO\nHYFgDke57Fyxu9MePXoAxePvbXvA0047rZIwE8Xee+GmJDbvJQm8InfOuZRLbUVu436tLdvWD9ly\nyy1DeX6r6NLstddey/tsrCK3MdS2frmNnbdx42mayVlo/vz5QLCFW7l++eWXko/bCJ7mrtGSNNZX\nYHeeTbFVQW2tmabWpk/r3WtjGho//txzz1U5koZ5Re6ccymXiop86623XvP1vffeC8D+++8PNNzW\nPW/ePAB+/PHHvMeHDRsGwIoVK4BgB5TCSqPcTXirzcZ8V7I6o/W2H3vssUBQWRx88MFA0M+Q5h1v\nWsrayo2Ni/7000/jCCd0tkOWrbNTeN6vv/76QLAKaHPXnbfnryVXXnll3rGt3f7uu+/GEU5JXpE7\n51zKJboit9X4zjvvvDWP2Wp0ttPL4sWLgaB6tEp62rRpQFCZN+Snn37KO7aVF21d5qSwmYjWjp07\nhnXAgAEVPff1118PwEEHHQSke4/OSp111ll5xy+++CIA7733XhzhhM76AOz8sf9rW3/c7vhsVEq5\nrDq139laUjjCx+7yC+/e4tRkRS4im4nIKyLykYjMFpELs49vKCIvisin2c8dow83Nf7oOSniOSnW\n039/inlOmq+cinwlcImqzhSR9YAZIvIicBowWVVHishQYCjw72EG17dvXyCowgEmTpwIBJVp4YiM\nctn+ezbG2ljbeYWztj4EJhNCTqxCsr6Bb7/9Fqi8CodgfKztz9hQf0NIQstJFGy0hbURm4j7CZaq\nas+ofn8aY//nhx12GBCsBlku6zt44IEHgKAd2c7PSsSVk0KdO3cGgh2BIv79qEiTFbmqLlTVmdmv\nlwJzgK7AEcC47I+NA46MKsiU8pwU85zks3nxnpdinpNmaFYbuYh0B3YG3gI6q+rC7Lf+CXQONTLg\n7LPPBoK9PCEY+1wpGwljf3VNiLO1QsmJ7Z9pbZlTpkyp9CnXjCO3Fe/suW3NlQjXkIjkPAmDVaS2\nRovtydncNUia6ffs56rnxUYq2egnW5e8IXZu2N629jnC9ctjP1dsxI7drVkObMZ0kpR9IReR9sDj\nwGBVXZJ7m6GqKiIl178UkYHAwEoDTRvPSTHPSWmel2Kek+Yp60IuIq3JXMT/rqq2lfo3ItJFVReK\nSBegZOOYqo4GRmefp1mLHdsKamFV4bls9TZjo19uv/32UJ4/rJxYH4Ct92yjV2ysNwQ7/hSu0mjt\n/3vttRcQVPc2k7NwfXJ772HloFBU50kY7rzzzrxjG70U8WqHrSFZebEZze+//z4AY8aMAaq/Y3yc\nOenWrRsAvXv3znt88uTJAEyaNCnsl6xYOaNWBBgDzFHVUTnfmgicmv36VOB/ww8v1TwnxTwn+Wwt\nWc9LMc9JM5RTke8BDABmiYgNpr0cGAk8KiJ/AeYBx0UTYir9EViM5ySX56TY+iLyKf77k8dz0nxN\nXshVdSrQ0Lib5q2FmQCzZs0Cgg4/88ILLwDw5ptvhvEyH6pqebv5NsE6Hq1j0ppFxo0bt+ZnrGmk\ncMqwddzZJgKFTSnGJgTZwlARCS0nUSjcnDm3gz1Cc1W1TzVeqCkXXHABAPfccw8Q72QXVe0Z24sD\nnTp1AoLNMoz9zrV0O7wo+RR955xLuURP0Y+Cbddky3naFP1bb701rpDKYltqWQdmnz5BIWcdUbak\nb+HmynZsCxpZlT9ixAgg2ObMBZI0/TpKDS3R6gJTp04FgsmISeQVuXPOpVzdVOS2QH67du2AYHiZ\nbUgRUtt4ZGzihm36YIsc5bL3MmFCZoRo4cYQNqwwSZvGJpUN87Tt74YPHx5nOK6KbKtDG/KbBumJ\n1DnnXEk1X5HbgjdDhgwBgqnX48ePB+DRRx+NJ7AWsirb2sxzlXrMlcdG7NjiTx06dACC/gfnkswr\ncuecSzmp5pjIOKZe2+gUW/DeNgiwDQMiMqPc8cFx5CQmnpNiZecE6icvqlr2erH1khOaOFe8InfO\nuZSr+TbylStXAnDTTTfFHIlzzkXDK3LnnEu5alfki4Bfsp9rwcaUfi9blHisIbWWEyidF89JZTmB\n2suL56RYi64pVe3sBBCRd5KyUFClwnovtZQTCOf9eE6ifZ4k8JwUa+l78aYV55xLOb+QO+dcysVx\nIR8dw2tGJaz3Uks5gXDej+ck2udJAs9JsRa9l6q3kTvnnAuXN60451zKVe1CLiJ/EpFPROQzERla\nrdcNi4hsJiKviMhHIjJbRC7MPn61iCwQkfeyH39u5vOmNi+ek2Kek9KiyIvnJIeqRv4BtAL+AWwJ\ntAHeB7avxmuH+B66AL2zX68HzAW2B64G/q0e8+I58ZzElRfPSf5HtSry3YDPVPVzVf0NeBg4okqv\nHQpVXaiqM7NfLwXmAF0b/1dNSnVePCfFPCelRZAXz0mOal3IuwJf5RzPp/KTOzYi0h3YGXgr+9Ag\nEflARMaKSMdmPFXN5MVzUsxzUlpIefGc5PDOzmYSkfbA48BgVV0C/CewFdALWAjcEmN4sfCcFPOc\nlOZ5KRZGTqp1IV8AbJZz3C37WKqISGsyCf+7qk4AUNVvVHWVqq4G7idzy1eu1OfFc1LMc1JayHnx\nnOSo1oV8OtBTRHqISBvgBGBilV47FCIiwBhgjqqOynm8S86PHQV82IynTXVePCfFPCelRZAXz0mO\nqqx+qKorRWQQMIlMb/NYVZ1djdcO0R7AAGCWiLyXfexyoL+I9AIU+AI4q9wnrIG8eE6KeU5KCzUv\nnpN8PrPTOedSzjs7nXMu5fxC7pxzKecXcuecSzm/kDvnXMr5hdw551LOL+TOOZdyfiF3zrmU8wu5\nc86l3P8DknTsL8LLi0MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDsoBdtoP7fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_net(data):\n",
        "  # print(data.get_shape())\n",
        "  # input = tf.reshape(data, [-1, 28, 28, 1])\n",
        "  # print(\"hello mr sandman\", tf.shape(data))\n",
        "  \n",
        "  # Convolutional Layer #1\n",
        "  conv1 = tf.layers.conv2d(\n",
        "      inputs=data,\n",
        "      filters=32,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"valid\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  # Convolutional Layer #2\n",
        "  conv2 = tf.layers.conv2d(\n",
        "      inputs=conv1,\n",
        "      filters=32,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"valid\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  pool1 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "\n",
        "  # Convolutional Layer #3\n",
        "  conv3 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=64,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"valid\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  # Convolutional Layer #4\n",
        "  conv4 = tf.layers.conv2d(\n",
        "      inputs=conv3,\n",
        "      filters=64,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"valid\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  # Convolutional Layer #5\n",
        "  conv5 = tf.layers.conv2d(\n",
        "      inputs=conv4,\n",
        "      filters=128,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"valid\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  # Convolutional Layer #6\n",
        "  conv6 = tf.layers.conv2d(\n",
        "      inputs=conv5,\n",
        "      filters=10,\n",
        "      kernel_size=[3, 3],\n",
        "      padding=\"valid\",\n",
        "      activation=tf.nn.relu)\n",
        "\n",
        "  # pool2 = tf.layers.max_pooling2d(inputs=conv6, pool_size=[4, 4], strides=4)\n",
        "  pool2 = tf.reduce_max(input_tensor = conv6, axis = [1,2])\n",
        "\n",
        "  flat = tf.reshape(pool2, [-1, 10])\n",
        "\n",
        "  # prediction\n",
        "  predictions = tf.nn.softmax(flat)\n",
        "  return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E072aXE4Qee_",
        "colab_type": "code",
        "outputId": "044b7bd8-3ca7-4645-e176-e47e744d5f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "predictions = conv_net(mn.tf_complicater(xs))\n",
        "\n",
        "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(predictions), reduction_indices=[1]))\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=predictions, labels=ys)\n",
        "\n",
        "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
        "\n",
        "# compute the accuracy\n",
        "correct_predictions = tf.equal(tf.argmax(predictions, 1), tf.argmax(ys, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "\n",
        "tmp = 0\n",
        "loss_log = []"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-1e708d290c6a>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-4-1e708d290c6a>:22: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AN3ibf4Q7F1",
        "colab_type": "code",
        "outputId": "5668830d-aaa6-48ef-fd92-bc3fcfd22621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import mnist_handling as mn\n",
        "import time\n",
        "t = time.clock()\n",
        "with tf.Session() as sess:\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess.run(init)\n",
        "\n",
        "    for i in range(30000):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(256)\n",
        "        batch_xs = batch_xs\n",
        "        los = sess.run(cross_entropy, feed_dict={xs: batch_xs, ys: batch_ys})\n",
        "        loss_log.append(los)\n",
        "\n",
        "        sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            \n",
        "            acc = sess.run(accuracy, feed_dict={\n",
        "                xs: mnist.test.images,\n",
        "                ys: mnist.test.labels\n",
        "            })\n",
        "            print(\"steps : %d \" % (i + 1), \"accuracy: \", acc, \"time: \", time.clock() - t, \"  \", time.clock())\n",
        "            t = time.clock()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "steps : 100  accuracy:  0.6369 time:  6.411026    11.555954\n",
            "steps : 200  accuracy:  0.6779 time:  2.3437329999999985    13.899967\n",
            "steps : 300  accuracy:  0.6905 time:  2.432714999999998    16.333048\n",
            "steps : 400  accuracy:  0.6941 time:  2.3093010000000014    18.644028\n",
            "steps : 500  accuracy:  0.7761 time:  2.371829999999999    21.016042\n",
            "steps : 600  accuracy:  0.7862 time:  2.319966000000001    23.337479\n",
            "steps : 700  accuracy:  0.7878 time:  2.3680909999999997    25.705796\n",
            "steps : 800  accuracy:  0.7905 time:  2.324932999999998    28.030912\n",
            "steps : 900  accuracy:  0.7963 time:  2.3903890000000025    30.421522\n",
            "steps : 1000  accuracy:  0.7959 time:  2.3506220000000013    32.773615\n",
            "steps : 1100  accuracy:  0.7972 time:  2.4055950000000053    35.180659\n",
            "steps : 1200  accuracy:  0.7963 time:  2.3030370000000033    37.483906\n",
            "steps : 1300  accuracy:  0.8747 time:  2.3739550000000023    39.858146\n",
            "steps : 1400  accuracy:  0.8809 time:  2.342901000000005    42.201253\n",
            "steps : 1500  accuracy:  0.8746 time:  2.310932000000001    44.512399\n",
            "steps : 1600  accuracy:  0.8851 time:  2.383851    46.897647\n",
            "steps : 1700  accuracy:  0.8818 time:  2.345019999999998    49.242894\n",
            "steps : 1800  accuracy:  0.8846 time:  2.3965419999999966    51.639631\n",
            "steps : 1900  accuracy:  0.887 time:  2.3215450000000004    53.961859\n",
            "steps : 2000  accuracy:  0.8854 time:  2.412835000000001    56.374904\n",
            "steps : 2100  accuracy:  0.884 time:  2.361291999999999    58.737789\n",
            "steps : 2200  accuracy:  0.8887 time:  2.424635000000002    61.163908\n",
            "steps : 2300  accuracy:  0.8887 time:  2.3830099999999987    63.548492\n",
            "steps : 2400  accuracy:  0.8882 time:  2.4004930000000044    65.950164\n",
            "steps : 2500  accuracy:  0.8865 time:  2.350881000000001    68.30127\n",
            "steps : 2600  accuracy:  0.8887 time:  2.414880999999994    70.716422\n",
            "steps : 2700  accuracy:  0.8881 time:  2.3371179999999896    73.055\n",
            "steps : 2800  accuracy:  0.8886 time:  2.4175690000000003    75.473758\n",
            "steps : 2900  accuracy:  0.8878 time:  2.343429999999998    77.818661\n",
            "steps : 3000  accuracy:  0.889 time:  2.31815499999999    80.138201\n",
            "steps : 3100  accuracy:  0.8881 time:  2.3804639999999893    82.520191\n",
            "steps : 3200  accuracy:  0.98 time:  2.3096929999999958    84.831593\n",
            "steps : 3300  accuracy:  0.9777 time:  2.3619429999999966    87.195056\n",
            "steps : 3400  accuracy:  0.9787 time:  2.283721    89.479018\n",
            "steps : 3500  accuracy:  0.9742 time:  2.374430000000004    91.853615\n",
            "steps : 3600  accuracy:  0.9817 time:  2.316993999999994    94.171195\n",
            "steps : 3700  accuracy:  0.9841 time:  2.390467000000001    96.561847\n",
            "steps : 3800  accuracy:  0.9834 time:  2.3228369999999927    98.885325\n",
            "steps : 3900  accuracy:  0.9848 time:  2.3713580000000007    101.257457\n",
            "steps : 4000  accuracy:  0.9775 time:  2.316447999999994    103.575292\n",
            "steps : 4100  accuracy:  0.9828 time:  2.401034999999993    105.976543\n",
            "steps : 4200  accuracy:  0.9836 time:  2.338009999999997    108.314837\n",
            "steps : 4300  accuracy:  0.9856 time:  2.3761730000000085    110.692507\n",
            "steps : 4400  accuracy:  0.9792 time:  2.3085610000000116    113.002582\n",
            "steps : 4500  accuracy:  0.9791 time:  2.3170789999999926    115.321136\n",
            "steps : 4600  accuracy:  0.9826 time:  2.370660000000001    117.691969\n",
            "steps : 4700  accuracy:  0.9865 time:  2.323617000000013    120.016331\n",
            "steps : 4800  accuracy:  0.9845 time:  2.365321999999992    122.381825\n",
            "steps : 4900  accuracy:  0.9824 time:  2.318123    124.70013\n",
            "steps : 5000  accuracy:  0.9844 time:  2.385486    127.086309\n",
            "steps : 5100  accuracy:  0.9867 time:  2.3093139999999863    129.395823\n",
            "steps : 5200  accuracy:  0.9869 time:  2.392756999999989    131.790177\n",
            "steps : 5300  accuracy:  0.9853 time:  2.3177900000000022    134.10819\n",
            "steps : 5400  accuracy:  0.9841 time:  2.3745529999999917    136.483018\n",
            "steps : 5500  accuracy:  0.9882 time:  2.324160000000006    138.808421\n",
            "steps : 5600  accuracy:  0.985 time:  2.398951000000011    141.207563\n",
            "steps : 5700  accuracy:  0.9863 time:  2.3313660000000027    143.539153\n",
            "steps : 5800  accuracy:  0.9867 time:  2.3033939999999973    145.842734\n",
            "steps : 5900  accuracy:  0.9869 time:  2.4123620000000017    148.255659\n",
            "steps : 6000  accuracy:  0.9849 time:  2.296647000000007    150.553764\n",
            "steps : 6100  accuracy:  0.9867 time:  2.3886269999999854    152.943879\n",
            "steps : 6200  accuracy:  0.9845 time:  2.311267000000015    155.255397\n",
            "steps : 6300  accuracy:  0.984 time:  2.392751000000004    157.649546\n",
            "steps : 6400  accuracy:  0.9836 time:  2.3003789999999924    159.951309\n",
            "steps : 6500  accuracy:  0.9863 time:  2.3552350000000217    162.307921\n",
            "steps : 6600  accuracy:  0.9844 time:  2.2989290000000153    164.608275\n",
            "steps : 6700  accuracy:  0.9834 time:  2.3760699999999986    166.985705\n",
            "steps : 6800  accuracy:  0.9851 time:  2.320751999999999    169.307753\n",
            "steps : 6900  accuracy:  0.9853 time:  2.391912999999988    171.701156\n",
            "steps : 7000  accuracy:  0.9873 time:  2.3274120000000096    174.028903\n",
            "steps : 7100  accuracy:  0.987 time:  2.38234700000001    176.412895\n",
            "steps : 7200  accuracy:  0.9857 time:  2.323294000000004    178.737655\n",
            "steps : 7300  accuracy:  0.9877 time:  2.283167999999989    181.021012\n",
            "steps : 7400  accuracy:  0.9878 time:  2.383741999999984    183.406113\n",
            "steps : 7500  accuracy:  0.9884 time:  2.3248279999999966    185.731124\n",
            "steps : 7600  accuracy:  0.987 time:  2.4023169999999823    188.134084\n",
            "steps : 7700  accuracy:  0.9877 time:  2.309240999999986    190.444794\n",
            "steps : 7800  accuracy:  0.9883 time:  2.367808999999994    192.81381\n",
            "steps : 7900  accuracy:  0.9878 time:  2.334998000000013    195.148991\n",
            "steps : 8000  accuracy:  0.9869 time:  2.388629999999978    197.537856\n",
            "steps : 8100  accuracy:  0.9863 time:  2.319371000000018    199.85744\n",
            "steps : 8200  accuracy:  0.9879 time:  2.389366999999993    202.24698\n",
            "steps : 8300  accuracy:  0.9862 time:  2.3326080000000218    204.579781\n",
            "steps : 8400  accuracy:  0.9886 time:  2.411545999999987    206.991542\n",
            "steps : 8500  accuracy:  0.988 time:  2.3298940000000243    209.322001\n",
            "steps : 8600  accuracy:  0.9842 time:  2.402413999999993    211.724598\n",
            "steps : 8700  accuracy:  0.9847 time:  2.3148129999999867    214.040106\n",
            "steps : 8800  accuracy:  0.9877 time:  2.305970000000002    216.346311\n",
            "steps : 8900  accuracy:  0.9853 time:  2.3380909999999915    218.685807\n",
            "steps : 9000  accuracy:  0.983 time:  2.2997040000000197    220.985727\n",
            "steps : 9100  accuracy:  0.989 time:  2.3654630000000054    223.351378\n",
            "steps : 9200  accuracy:  0.9882 time:  2.3178020000000004    225.669356\n",
            "steps : 9300  accuracy:  0.9846 time:  2.37469999999999    228.044263\n",
            "steps : 9400  accuracy:  0.9872 time:  2.2995679999999936    230.345195\n",
            "steps : 9500  accuracy:  0.9857 time:  2.382515999999981    232.728509\n",
            "steps : 9600  accuracy:  0.985 time:  2.3251049999999793    235.054966\n",
            "steps : 9700  accuracy:  0.9846 time:  2.3650599999999997    237.421412\n",
            "steps : 9800  accuracy:  0.9834 time:  2.2736749999999972    239.695266\n",
            "steps : 9900  accuracy:  0.9848 time:  2.369135    242.065963\n",
            "steps : 10000  accuracy:  0.9855 time:  2.311647999999991    244.377914\n",
            "steps : 10100  accuracy:  0.9874 time:  2.3700979999999845    246.748198\n",
            "steps : 10200  accuracy:  0.9807 time:  2.330982000000006    249.079503\n",
            "steps : 10300  accuracy:  0.9856 time:  2.3299539999999865    251.411075\n",
            "steps : 10400  accuracy:  0.9849 time:  2.383312000000018    253.795851\n",
            "steps : 10500  accuracy:  0.9882 time:  2.320569000000006    256.117754\n",
            "steps : 10600  accuracy:  0.986 time:  2.378975999999966    258.496924\n",
            "steps : 10700  accuracy:  0.9836 time:  2.305593999999985    260.802735\n",
            "steps : 10800  accuracy:  0.9829 time:  2.4039019999999596    263.20683\n",
            "steps : 10900  accuracy:  0.9848 time:  2.313999000000024    265.52227\n",
            "steps : 11000  accuracy:  0.988 time:  2.3705770000000257    267.893033\n",
            "steps : 11100  accuracy:  0.986 time:  2.285125999999991    270.179552\n",
            "steps : 11200  accuracy:  0.987 time:  2.364036999999996    272.545066\n",
            "steps : 11300  accuracy:  0.9822 time:  2.2851249999999936    274.83166\n",
            "steps : 11400  accuracy:  0.9847 time:  2.359511999999995    277.191461\n",
            "steps : 11500  accuracy:  0.987 time:  2.2969490000000405    279.489821\n",
            "steps : 11600  accuracy:  0.9862 time:  2.283974999999998    281.773993\n",
            "steps : 11700  accuracy:  0.9854 time:  2.375633999999991    284.151033\n",
            "steps : 11800  accuracy:  0.9861 time:  2.3143210000000067    286.465551\n",
            "steps : 11900  accuracy:  0.9867 time:  2.359946999999977    288.825705\n",
            "steps : 12000  accuracy:  0.9869 time:  2.3131779999999935    291.139192\n",
            "steps : 12100  accuracy:  0.9852 time:  2.3046150000000125    293.445119\n",
            "steps : 12200  accuracy:  0.9883 time:  2.2803539999999884    295.726937\n",
            "steps : 12300  accuracy:  0.9881 time:  2.3823170000000005    298.110793\n",
            "steps : 12400  accuracy:  0.9837 time:  2.2832910000000197    300.394273\n",
            "steps : 12500  accuracy:  0.9872 time:  2.376121000000012    302.770664\n",
            "steps : 12600  accuracy:  0.9897 time:  2.3330510000000118    305.105104\n",
            "steps : 12700  accuracy:  0.9885 time:  2.352073999999959    307.457369\n",
            "steps : 12800  accuracy:  0.987 time:  2.3175790000000234    309.776517\n",
            "steps : 12900  accuracy:  0.9871 time:  2.3375750000000153    312.114307\n",
            "steps : 13000  accuracy:  0.9867 time:  2.3416839999999866    314.456198\n",
            "steps : 13100  accuracy:  0.9891 time:  2.3089789999999653    316.76672\n",
            "steps : 13200  accuracy:  0.9866 time:  2.365955999999983    319.132866\n",
            "steps : 13300  accuracy:  0.9877 time:  2.3096570000000156    321.443858\n",
            "steps : 13400  accuracy:  0.9875 time:  2.334536000000014    323.778601\n",
            "steps : 13500  accuracy:  0.9861 time:  2.322381000000007    326.101783\n",
            "steps : 13600  accuracy:  0.9866 time:  2.3908289999999965    328.492805\n",
            "steps : 13700  accuracy:  0.9846 time:  2.365243000000021    330.859178\n",
            "steps : 13800  accuracy:  0.9857 time:  2.3625260000000026    333.222866\n",
            "steps : 13900  accuracy:  0.9827 time:  2.3218250000000467    335.546086\n",
            "steps : 14000  accuracy:  0.9861 time:  2.3598629999999616    337.906173\n",
            "steps : 14100  accuracy:  0.9855 time:  2.2958849999999984    340.203107\n",
            "steps : 14200  accuracy:  0.9874 time:  2.342612000000031    342.547238\n",
            "steps : 14300  accuracy:  0.9859 time:  2.279305000000022    344.827997\n",
            "steps : 14400  accuracy:  0.9832 time:  2.3836670000000026    347.211868\n",
            "steps : 14500  accuracy:  0.9812 time:  2.334182999999996    349.546246\n",
            "steps : 14600  accuracy:  0.9857 time:  2.3177780000000325    351.864232\n",
            "steps : 14700  accuracy:  0.9844 time:  2.3593660000000227    354.225149\n",
            "steps : 14800  accuracy:  0.9842 time:  2.3049330000000054    356.53028\n",
            "steps : 14900  accuracy:  0.9862 time:  2.3780419999999935    358.908512\n",
            "steps : 15000  accuracy:  0.9882 time:  2.298466000000019    361.207173\n",
            "steps : 15100  accuracy:  0.9886 time:  2.3585639999999444    363.566591\n",
            "steps : 15200  accuracy:  0.9847 time:  2.339623999999958    365.906423\n",
            "steps : 15300  accuracy:  0.9859 time:  2.3851209999999696    368.292347\n",
            "steps : 15400  accuracy:  0.9825 time:  2.3152789999999754    370.607854\n",
            "steps : 15500  accuracy:  0.9837 time:  2.3774480000000153    372.985659\n",
            "steps : 15600  accuracy:  0.9889 time:  2.3011580000000436    375.287035\n",
            "steps : 15700  accuracy:  0.9872 time:  2.3659509999999955    377.653189\n",
            "steps : 15800  accuracy:  0.9883 time:  2.3181370000000356    379.971535\n",
            "steps : 15900  accuracy:  0.9892 time:  2.387788999999998    382.359497\n",
            "steps : 16000  accuracy:  0.9889 time:  2.3041150000000243    384.663864\n",
            "steps : 16100  accuracy:  0.9881 time:  2.3178310000000124    386.981885\n",
            "steps : 16200  accuracy:  0.9878 time:  2.3926440000000184    389.374706\n",
            "steps : 16300  accuracy:  0.9833 time:  2.3184329999999704    391.693699\n",
            "steps : 16400  accuracy:  0.9817 time:  2.380673999999999    394.074723\n",
            "steps : 16500  accuracy:  0.9874 time:  2.288295000000005    396.364364\n",
            "steps : 16600  accuracy:  0.9864 time:  2.366427999999985    398.73217\n",
            "steps : 16700  accuracy:  0.9839 time:  2.304924999999969    401.038698\n",
            "steps : 16800  accuracy:  0.978 time:  2.3941370000000006    403.433069\n",
            "steps : 16900  accuracy:  0.9803 time:  2.3439109999999914    405.777176\n",
            "steps : 17000  accuracy:  0.9786 time:  2.372445999999968    408.151149\n",
            "steps : 17100  accuracy:  0.9861 time:  2.310849000000019    410.462904\n",
            "steps : 17200  accuracy:  0.9862 time:  2.404465000000016    412.867596\n",
            "steps : 17300  accuracy:  0.9854 time:  2.318148000000008    415.187204\n",
            "steps : 17400  accuracy:  0.9876 time:  2.3243400000000065    417.511738\n",
            "steps : 17500  accuracy:  0.9829 time:  2.370533000000023    419.882474\n",
            "steps : 17600  accuracy:  0.9874 time:  2.3245810000000233    422.207229\n",
            "steps : 17700  accuracy:  0.9877 time:  2.377239999999972    424.584708\n",
            "steps : 17800  accuracy:  0.9864 time:  2.296644000000015    426.88155\n",
            "steps : 17900  accuracy:  0.9884 time:  2.3680400000000077    429.249865\n",
            "steps : 18000  accuracy:  0.9851 time:  2.2632770000000164    431.513347\n",
            "steps : 18100  accuracy:  0.9766 time:  2.3487220000000093    433.862282\n",
            "steps : 18200  accuracy:  0.987 time:  2.3022100000000023    436.16467\n",
            "steps : 18300  accuracy:  0.9854 time:  2.369150999999988    438.534688\n",
            "steps : 18400  accuracy:  0.986 time:  2.3179000000000087    440.852882\n",
            "steps : 18500  accuracy:  0.9855 time:  2.373302000000024    443.226388\n",
            "steps : 18600  accuracy:  0.9864 time:  2.3295350000000212    445.557302\n",
            "steps : 18700  accuracy:  0.9857 time:  2.4006899999999973    447.959029\n",
            "steps : 18800  accuracy:  0.9846 time:  2.320233999999971    450.279466\n",
            "steps : 18900  accuracy:  0.9765 time:  2.317003999999997    452.5978\n",
            "steps : 19000  accuracy:  0.9756 time:  2.389004    454.987041\n",
            "steps : 19100  accuracy:  0.983 time:  2.311559999999986    457.298868\n",
            "steps : 19200  accuracy:  0.9841 time:  2.384475000000009    459.683543\n",
            "steps : 19300  accuracy:  0.976 time:  2.2994360000000142    461.984229\n",
            "steps : 19400  accuracy:  0.986 time:  2.3535099999999716    464.339144\n",
            "steps : 19500  accuracy:  0.9877 time:  2.3190989999999942    466.659538\n",
            "steps : 19600  accuracy:  0.9876 time:  2.375618999999972    469.035423\n",
            "steps : 19700  accuracy:  0.9851 time:  2.318981000000008    471.354612\n",
            "steps : 19800  accuracy:  0.9796 time:  2.3796760000000177    473.735531\n",
            "steps : 19900  accuracy:  0.9836 time:  2.3144700000000284    476.050201\n",
            "steps : 20000  accuracy:  0.9848 time:  2.3918150000000082    478.442294\n",
            "steps : 20100  accuracy:  0.9852 time:  2.305056000000036    480.747545\n",
            "steps : 20200  accuracy:  0.9882 time:  2.3653600000000097    483.11312\n",
            "steps : 20300  accuracy:  0.9879 time:  2.329165000000046    485.442451\n",
            "steps : 20400  accuracy:  0.9898 time:  2.3229290000000447    487.765556\n",
            "steps : 20500  accuracy:  0.9876 time:  2.378399999999999    490.144138\n",
            "steps : 20600  accuracy:  0.9868 time:  2.3382199999999784    492.482558\n",
            "steps : 20700  accuracy:  0.9849 time:  2.3893390000000068    494.872082\n",
            "steps : 20800  accuracy:  0.9785 time:  2.328624999999988    497.200885\n",
            "steps : 20900  accuracy:  0.9841 time:  2.407485999999949    499.609955\n",
            "steps : 21000  accuracy:  0.9855 time:  2.3232039999999756    501.934719\n",
            "steps : 21100  accuracy:  0.9864 time:  2.370857000000001    504.305766\n",
            "steps : 21200  accuracy:  0.9838 time:  2.3200239999999894    506.62634\n",
            "steps : 21300  accuracy:  0.9863 time:  2.381562000000031    509.009233\n",
            "steps : 21400  accuracy:  0.9831 time:  2.291181999999992    511.300604\n",
            "steps : 21500  accuracy:  0.9814 time:  2.393606000000034    513.694432\n",
            "steps : 21600  accuracy:  0.9851 time:  2.2985009999999875    515.994594\n",
            "steps : 21700  accuracy:  0.9804 time:  2.3565939999999728    518.351378\n",
            "steps : 21800  accuracy:  0.9772 time:  2.338702000000012    520.690739\n",
            "steps : 21900  accuracy:  0.9817 time:  2.3444809999999734    523.036037\n",
            "steps : 22000  accuracy:  0.9812 time:  2.4002020000000357    525.436427\n",
            "steps : 22100  accuracy:  0.9759 time:  2.321843999999942    527.758473\n",
            "steps : 22200  accuracy:  0.9723 time:  2.3835449999999128    530.142676\n",
            "steps : 22300  accuracy:  0.9726 time:  2.3147290000000567    532.457583\n",
            "steps : 22400  accuracy:  0.9724 time:  2.3584600000000364    534.816585\n",
            "steps : 22500  accuracy:  0.9878 time:  2.3067579999999452    537.124793\n",
            "steps : 22600  accuracy:  0.9843 time:  2.3830050000000256    539.508052\n",
            "steps : 22700  accuracy:  0.9873 time:  2.3207859999999982    541.830212\n",
            "steps : 22800  accuracy:  0.9752 time:  2.366910999999959    544.198579\n",
            "steps : 22900  accuracy:  0.9845 time:  2.2941800000000967    546.494266\n",
            "steps : 23000  accuracy:  0.979 time:  2.372795999999994    548.867283\n",
            "steps : 23100  accuracy:  0.982 time:  2.298913999999968    551.167564\n",
            "steps : 23200  accuracy:  0.9823 time:  2.298419000000081    553.466168\n",
            "steps : 23300  accuracy:  0.9839 time:  2.377126999999973    555.844672\n",
            "steps : 23400  accuracy:  0.9525 time:  2.3170950000001085    558.163168\n",
            "steps : 23500  accuracy:  0.9797 time:  2.3956280000001016    560.558973\n",
            "steps : 23600  accuracy:  0.9812 time:  2.32544699999994    562.884612\n",
            "steps : 23700  accuracy:  0.9804 time:  2.3460910000000013    565.232135\n",
            "steps : 23800  accuracy:  0.9749 time:  2.3401620000000776    567.573657\n",
            "steps : 23900  accuracy:  0.9771 time:  2.4075820000000476    569.98144\n",
            "steps : 24000  accuracy:  0.9811 time:  2.301832999999988    572.284155\n",
            "steps : 24100  accuracy:  0.9784 time:  2.367796999999996    574.653348\n",
            "steps : 24200  accuracy:  0.9757 time:  2.3029339999999365    576.956471\n",
            "steps : 24300  accuracy:  0.9817 time:  2.3843460000000505    579.340989\n",
            "steps : 24400  accuracy:  0.9766 time:  2.303865999999971    581.645048\n",
            "steps : 24500  accuracy:  0.9792 time:  2.3634360000000925    584.009931\n",
            "steps : 24600  accuracy:  0.9836 time:  2.30605700000001    586.316187\n",
            "steps : 24700  accuracy:  0.9862 time:  2.3286150000000134    588.645355\n",
            "steps : 24800  accuracy:  0.987 time:  2.36081200000001    591.00754\n",
            "steps : 24900  accuracy:  0.9782 time:  2.3177180000000135    593.325435\n",
            "steps : 25000  accuracy:  0.9827 time:  2.4011169999999993    595.72818\n",
            "steps : 25100  accuracy:  0.9746 time:  2.354217999999946    598.083941\n",
            "steps : 25200  accuracy:  0.9783 time:  2.4291090000000395    600.51441\n",
            "steps : 25300  accuracy:  0.9807 time:  2.32201299999997    602.837764\n",
            "steps : 25400  accuracy:  0.9801 time:  2.3608619999999974    605.198843\n",
            "steps : 25500  accuracy:  0.982 time:  2.3038669999999684    607.50415\n",
            "steps : 25600  accuracy:  0.9833 time:  2.3865939999999455    609.890994\n",
            "steps : 25700  accuracy:  0.9727 time:  2.326505999999995    612.219029\n",
            "steps : 25800  accuracy:  0.9804 time:  2.3767380000000458    614.597116\n",
            "steps : 25900  accuracy:  0.9849 time:  2.321831999999972    616.920365\n",
            "steps : 26000  accuracy:  0.984 time:  2.3585389999999506    619.280222\n",
            "steps : 26100  accuracy:  0.988 time:  2.2893349999999373    621.57107\n",
            "steps : 26200  accuracy:  0.9823 time:  2.3114249999999856    623.882666\n",
            "steps : 26300  accuracy:  0.9834 time:  2.3540140000000065    626.238199\n",
            "steps : 26400  accuracy:  0.9779 time:  2.3050739999999905    628.543458\n",
            "steps : 26500  accuracy:  0.9793 time:  2.376655000000028    630.920285\n",
            "steps : 26600  accuracy:  0.9852 time:  2.3097799999999324    633.230244\n",
            "steps : 26700  accuracy:  0.9837 time:  2.3738050000000612    635.604228\n",
            "steps : 26800  accuracy:  0.9862 time:  2.3143420000000106    637.918746\n",
            "steps : 26900  accuracy:  0.9721 time:  2.3577830000000404    640.276714\n",
            "steps : 27000  accuracy:  0.983 time:  2.295376000000033    642.572641\n",
            "steps : 27100  accuracy:  0.9816 time:  2.348239999999919    644.922432\n",
            "steps : 27200  accuracy:  0.9763 time:  2.318516999999929    647.24236\n",
            "steps : 27300  accuracy:  0.9822 time:  2.3802630000000136    649.622797\n",
            "steps : 27400  accuracy:  0.9761 time:  2.3014530000000377    651.925707\n",
            "steps : 27500  accuracy:  0.9825 time:  2.312379999999962    654.238271\n",
            "steps : 27600  accuracy:  0.9827 time:  2.373408999999924    656.611925\n",
            "steps : 27700  accuracy:  0.9848 time:  2.3057509999999866    658.91785\n",
            "steps : 27800  accuracy:  0.9854 time:  2.3737820000000056    661.291827\n",
            "steps : 27900  accuracy:  0.9766 time:  2.2957079999999905    663.58798\n",
            "steps : 28000  accuracy:  0.9828 time:  2.3778749999999036    665.966076\n",
            "steps : 28100  accuracy:  0.9821 time:  2.2823150000000396    668.248608\n",
            "steps : 28200  accuracy:  0.9749 time:  2.3984480000000303    670.647279\n",
            "steps : 28300  accuracy:  0.9708 time:  2.341803999999911    672.989305\n",
            "steps : 28400  accuracy:  0.9673 time:  2.3558590000000095    675.346366\n",
            "steps : 28500  accuracy:  0.9779 time:  2.3324479999999994    677.678986\n",
            "steps : 28600  accuracy:  0.9689 time:  2.3686159999999745    680.047834\n",
            "steps : 28700  accuracy:  0.9839 time:  2.316090000000031    682.364144\n",
            "steps : 28800  accuracy:  0.9856 time:  2.406213999999977    684.771992\n",
            "steps : 28900  accuracy:  0.9803 time:  2.3029769999999417    687.076397\n",
            "steps : 29000  accuracy:  0.9714 time:  2.2997629999999845    689.377621\n",
            "steps : 29100  accuracy:  0.9801 time:  2.3694560000000138    691.748256\n",
            "steps : 29200  accuracy:  0.9812 time:  2.2823450000000776    694.032096\n",
            "steps : 29300  accuracy:  0.9764 time:  2.3680269999999837    696.400298\n",
            "steps : 29400  accuracy:  0.9809 time:  2.298091999999997    698.699681\n",
            "steps : 29500  accuracy:  0.9799 time:  2.398050000000012    701.097929\n",
            "steps : 29600  accuracy:  0.9599 time:  2.3252279999999246    703.424458\n",
            "steps : 29700  accuracy:  0.9787 time:  2.3517989999999145    705.777583\n",
            "steps : 29800  accuracy:  0.9784 time:  2.316022999999973    708.094884\n",
            "steps : 29900  accuracy:  0.9763 time:  2.3503500000000486    710.445464\n",
            "steps : 30000  accuracy:  0.9787 time:  2.3422689999999875    712.789149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYW8J7ftRUKZ",
        "colab_type": "code",
        "outputId": "41d9250a-d9df-4607-ae7c-6435e4d002b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot([a.mean() for a in loss_log])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAW6iEiKUKCLiKSI/w9U+pIejRIFbwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNuo_M_jqlQH",
        "colab_type": "code",
        "outputId": "8ea95d33-f632-4edc-f43e-969c0a13eb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from skimage.transform import resize\n",
        "im = batch_xs[13,:,:,0].copy()\n",
        "# for i in range(len(im)):\n",
        "#   for j in range(len(im[i])):\n",
        "#     # im[i,j] = im[i,j]\n",
        "#     im[i,j] = im[i,j] + random.gauss(0,0.1) \n",
        "\n",
        "im = resize\n",
        "(batch_xs, output_shape =  (256,40,40,1), anti_aliasing=False)\n",
        "plt.imshow(np.squeeze(im[3,:,:,0]), cmap='gray')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-08571ac8a5b6>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    (batch_xs, output_shape =  (256,40,40,1), anti_aliasing=False)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlspImK4orcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "5*1.75"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}